{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/centerformer/det3d/core/bbox/geometry.py:149: NumbaDeprecationWarning: The keyword argument 'nopython=False' was supplied. From Numba 0.59.0 the default is being changed to True and use of 'nopython=False' will raise a warning as the argument will have no effect. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit(nopython=False)\n",
      "/data/centerformer/det3d/core/bbox/geometry.py:162: NumbaDeprecationWarning: The keyword argument 'nopython=False' was supplied. From Numba 0.59.0 the default is being changed to True and use of 'nopython=False' will raise a warning as the argument will have no effect. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit(nopython=False)\n",
      "/data/centerformer/det3d/core/bbox/geometry.py:280: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def points_in_convex_polygon_jit(points, polygon, clockwise=True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deformable Convolution not built!\n",
      "Deformable Convolution not built!\n",
      "[12/15/2023-08:20:26] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\n",
      "Use HM Bias:  -2.19\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from det3d.torchie import Config\n",
    "from det3d.models import build_detector\n",
    "from det3d.torchie.trainer import load_checkpoint\n",
    "\n",
    "config = \"/workspace/centerformer/configs/nusc/nuscenes_centerformer_poolformer.py\"\n",
    "\n",
    "cfg = Config.fromfile(config)\n",
    "checkpoint_path = \"/workspace/centerformer/work_dirs/nuscenes_poolformer/poolformer.pth\"\n",
    "\n",
    "model = build_detector(cfg.model, train_cfg=None, test_cfg=cfg.test_cfg)\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location=\"cpu\")\n",
    "model.cuda()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_dir = \"/workspace/centerformer/work_dirs/partition/sample_data/\"\n",
    "\n",
    "with open(pickle_dir + \"findcenter_input.pkl\", 'rb') as handle:\n",
    "    x = pickle.load(handle)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ct_feat, center_pos_embedding, out_scores, out_labels, out_orders, out_masks = model.neck.find_centers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.5.1.7'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "trt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/15/2023-08:20:28] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\n"
     ]
    }
   ],
   "source": [
    "centerFinder_engine_path = '/workspace/centerformer/work_dirs/partition/engine/findCenter_folded.trt'\n",
    "\n",
    "\n",
    "def load_engine(engine_filepath):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "    with open(engine_filepath, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    return engine\n",
    "\n",
    "cf_engine = load_engine(centerFinder_engine_path)\n",
    "cf_context = cf_engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True, device='cuda:0') cuda:0\n"
     ]
    }
   ],
   "source": [
    "with open(pickle_dir + \"findcenter_input.pkl\", 'rb') as handle:\n",
    "    input_tensor = pickle.load(handle)\n",
    "print((x == input_tensor).all(), x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 180, 180])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_device = torch.device(\"cuda\")\n",
    "ct_feat_tensor = torch.zeros((1, 3000, 256), dtype=torch.float32, device=to_device)\n",
    "center_pos_embedding_tensor = torch.zeros((1, 3000, 256), dtype=torch.float32, device=to_device)\n",
    "out_scores_tensor = torch.zeros((6, 1, 500), dtype=torch.float32, device=to_device)\n",
    "out_labels_tensor = torch.zeros((6, 1, 500), dtype=torch.int32, device=to_device)\n",
    "out_orders_tensor = torch.zeros((6, 1, 500), dtype=torch.int32, device=to_device)\n",
    "out_masks_tensor = torch.zeros((6, 1, 500), dtype=torch.bool, device=to_device)\n",
    "IO_tensors = {\n",
    "    \"inputs\" :\n",
    "    {'input_tensor': input_tensor},\n",
    "    \"outputs\" :{\n",
    "        'out_labels': out_labels_tensor,\n",
    "        'ct_feat': ct_feat_tensor, \n",
    "        'center_pos_embedding': center_pos_embedding_tensor,\n",
    "        'out_scores': out_scores_tensor, \n",
    "        'out_orders': out_orders_tensor, \n",
    "        'out_masks': out_masks_tensor}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trt_engine(context, engine, tensors):\n",
    "    bindings = [None]*engine.num_bindings\n",
    "    for idx, binding in enumerate(engine):\n",
    "        tensor_name = engine.get_tensor_name(idx)\n",
    "        if engine.get_tensor_mode(binding)==trt.TensorIOMode.INPUT:\n",
    "            bindings[idx] = tensors['inputs'][tensor_name].data_ptr()\n",
    "            if context.get_tensor_shape(tensor_name):\n",
    "                context.set_input_shape(tensor_name, tensors['inputs'][tensor_name].shape)\n",
    "        else:\n",
    "            bindings[idx] = tensors['outputs'][tensor_name].data_ptr()\n",
    "    context.execute_v2(bindings=bindings)\n",
    "\n",
    "run_trt_engine(cf_context, cf_engine, IO_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8610, 0.8600, 0.8393, 0.8083, 0.8044, 0.7641, 0.7413, 0.7288, 0.7048,\n",
      "        0.6847], device='cuda:0')\n",
      "tensor([0.8610, 0.8600, 0.8393, 0.8083, 0.8044, 0.7641, 0.7413, 0.7288, 0.7048,\n",
      "        0.6847], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(out_scores[0][0][:10])\n",
    "print(out_scores_tensor[0][0][:10])#tensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 0.4185, 0.2847, 0.0000, 0.0000, 0.0000, 0.0000, 0.2222,\n",
      "        0.9349, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7531, 0.0000, 0.0000,\n",
      "        0.0000, 0.8260], device='cuda:0')\n",
      "tensor([0.0000, 0.0000, 0.4185, 0.2847, 0.0000, 0.0000, 0.0000, 0.0000, 0.2222,\n",
      "        0.9349, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7531, 0.0000, 0.0000,\n",
      "        0.0000, 0.8260], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(ct_feat[0][0][:20])\n",
    "print(ct_feat_tensor[0][0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([49866, 62040, 59169, 57018, 61680, 98445, 59170, 50226, 30777, 57017,\n",
      "        59529, 98446, 59530, 27541, 62041, 49867, 61679, 30776, 31137, 49506],\n",
      "       device='cuda:0')\n",
      "tensor([49866, 62040, 59169, 57018, 61680, 98445, 59170, 50226, 30777, 57017,\n",
      "        59529, 98446, 59530, 27541, 62041, 49867, 61679, 30776, 31137, 49506],\n",
      "       device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(out_orders[0][0][:20])\n",
    "print(out_orders_tensor[0][0][:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "centerformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
