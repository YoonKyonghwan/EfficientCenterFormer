{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deformable Convolution not built!\n",
      "Deformable Convolution not built!\n",
      "Use center number 500 in inference\n",
      "Use heatmap score threshold 0.03 in inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/centerformer/det3d/core/bbox/geometry.py:149: NumbaDeprecationWarning: The keyword argument 'nopython=False' was supplied. From Numba 0.59.0 the default is being changed to True and use of 'nopython=False' will raise a warning as the argument will have no effect. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit(nopython=False)\n",
      "/data/centerformer/det3d/core/bbox/geometry.py:162: NumbaDeprecationWarning: The keyword argument 'nopython=False' was supplied. From Numba 0.59.0 the default is being changed to True and use of 'nopython=False' will raise a warning as the argument will have no effect. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit(nopython=False)\n",
      "/data/centerformer/det3d/core/bbox/geometry.py:280: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def points_in_convex_polygon_jit(points, polygon, clockwise=True):\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import torch\n",
    "from det3d.torchie import Config\n",
    "from det3d.models import build_detector\n",
    "from det3d.torchie.trainer import load_checkpoint\n",
    "\n",
    "config = \"/workspace/centerformer/configs/nusc/nuscenes_centerformer_poolformer.py\"\n",
    "cfg = Config.fromfile(config)\n",
    "\n",
    "cfg.work_dir = \"/workspace/centerformer/work_dirs/nuscenes_poolformer\"\n",
    "if 'obj_num' in cfg.test_cfg:\n",
    "        cfg.model['neck']['obj_num'] = cfg.test_cfg['obj_num']\n",
    "        print('Use center number {} in inference'.format(cfg.model['neck']['obj_num']))\n",
    "if 'score_threshold' in cfg.test_cfg:\n",
    "    cfg.model['neck']['score_threshold'] = cfg.test_cfg['score_threshold']\n",
    "    print('Use heatmap score threshold {} in inference'.format(cfg.model['neck']['score_threshold']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use HM Bias:  -2.19\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"/workspace/centerformer/work_dirs/nuscenes_poolformer/poolformer.pth\"\n",
    "\n",
    "model = build_detector(cfg.model, train_cfg=None, test_cfg=cfg.test_cfg)\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location=\"cpu\")\n",
    "model.cuda()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no apex\n",
      "No Tensorflow\n",
      "Use Val Set\n",
      "use gt label assigning kernel size  1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from det3d.datasets import build_dataloader, build_dataset\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "os.chdir(\"/workspace/centerformer\")\n",
    "\n",
    "print(\"Use Val Set\")\n",
    "dataset = build_dataset(cfg.data.val)\n",
    "\n",
    "data_loader = build_dataloader(\n",
    "    dataset,\n",
    "    batch_size=cfg.data.samples_per_gpu,\n",
    "    workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "    dist=False,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/13/2023-16:47:25] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\n"
     ]
    }
   ],
   "source": [
    "def load_engine(engine_filepath):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "    with open(engine_filepath, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    return engine\n",
    "\n",
    "centerFinder_engine_path = 'findCenter.trt'\n",
    "cf_engine = load_engine(centerFinder_engine_path)\n",
    "cf_context = cf_engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trt_engine(context, engine, tensors):\n",
    "    bindings = [None]*engine.num_bindings\n",
    "    for idx, binding in enumerate(engine):\n",
    "        tensor_name = engine.get_tensor_name(idx)\n",
    "        if engine.get_tensor_mode(binding)==trt.TensorIOMode.INPUT:\n",
    "            bindings[idx] = tensors['inputs'][tensor_name].data_ptr()\n",
    "            if context.get_tensor_shape(tensor_name):\n",
    "                context.set_input_shape(tensor_name, tensors['inputs'][tensor_name].shape)\n",
    "        else:\n",
    "            bindings[idx] = tensors['outputs'][tensor_name].data_ptr()\n",
    "    context.execute_v2(bindings=bindings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No APEX!\n",
      "[                              ] 0/6019, elapsed: 0s, ETA:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/centerformer/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8610, 0.8600, 0.8393, 0.8083, 0.8044, 0.7641, 0.7413, 0.7288, 0.7048,\n",
      "         0.6847, 0.6831, 0.6785, 0.6444, 0.6397, 0.6353, 0.6312, 0.6230, 0.5880,\n",
      "         0.5813, 0.5762, 0.5750, 0.5687, 0.5622, 0.5600, 0.5405, 0.5021, 0.4977,\n",
      "         0.4964, 0.4836, 0.4738, 0.4396, 0.4358, 0.4336, 0.4208, 0.4134, 0.4042,\n",
      "         0.4001, 0.3994, 0.3968, 0.3764, 0.3758, 0.3660, 0.3656, 0.3572, 0.3466,\n",
      "         0.3457, 0.3433, 0.3372, 0.3363, 0.3348, 0.3094, 0.3040, 0.3037, 0.3031,\n",
      "         0.3031, 0.2965, 0.2842, 0.2781, 0.2743, 0.2723, 0.2705, 0.2680, 0.2657,\n",
      "         0.2657, 0.2646, 0.2628, 0.2578, 0.2462, 0.2393, 0.2391, 0.2384, 0.2338,\n",
      "         0.2336, 0.2317, 0.2279, 0.2277, 0.2254, 0.2220, 0.2208, 0.2204, 0.2197,\n",
      "         0.2185, 0.2176, 0.2067, 0.2008, 0.1964, 0.1943, 0.1932, 0.1913, 0.1866,\n",
      "         0.1856, 0.1832, 0.1827, 0.1806, 0.1770, 0.1770, 0.1758, 0.1746, 0.1738,\n",
      "         0.1730, 0.1728, 0.1724, 0.1720, 0.1719, 0.1707, 0.1667, 0.1661, 0.1639,\n",
      "         0.1632, 0.1630, 0.1620, 0.1604, 0.1601, 0.1589, 0.1580, 0.1579, 0.1559,\n",
      "         0.1554, 0.1543, 0.1531, 0.1510, 0.1506, 0.1505, 0.1505, 0.1504, 0.1489,\n",
      "         0.1488, 0.1466, 0.1456, 0.1446, 0.1444, 0.1444, 0.1438, 0.1426, 0.1421,\n",
      "         0.1405, 0.1383, 0.1381, 0.1381, 0.1373, 0.1369, 0.1366, 0.1356, 0.1355,\n",
      "         0.1354, 0.1347, 0.1341, 0.1340, 0.1339, 0.1334, 0.1333, 0.1325, 0.1321,\n",
      "         0.1309, 0.1306, 0.1303, 0.1301, 0.1293, 0.1291, 0.1289, 0.1288, 0.1284,\n",
      "         0.1283, 0.1281, 0.1273, 0.1269, 0.1267, 0.1263, 0.1247, 0.1237, 0.1229,\n",
      "         0.1221, 0.1212, 0.1203, 0.1202, 0.1201, 0.1199, 0.1199, 0.1197, 0.1196,\n",
      "         0.1193, 0.1187, 0.1177, 0.1176, 0.1175, 0.1174, 0.1171, 0.1162, 0.1159,\n",
      "         0.1135, 0.1135, 0.1131, 0.1128, 0.1125, 0.1121, 0.1117, 0.1110, 0.1104,\n",
      "         0.1103, 0.1100, 0.1085, 0.1082, 0.1082, 0.1076, 0.1076, 0.1059, 0.1057,\n",
      "         0.1048, 0.1043, 0.1043, 0.1043, 0.1037, 0.1033, 0.1030, 0.1030, 0.1024,\n",
      "         0.1015, 0.1010, 0.1010, 0.1006, 0.1002, 0.1000, 0.0999, 0.0999, 0.0998,\n",
      "         0.0992, 0.0991, 0.0990, 0.0985, 0.0984, 0.0984, 0.0981, 0.0978, 0.0976,\n",
      "         0.0976, 0.0974, 0.0974, 0.0973, 0.0963, 0.0963, 0.0963, 0.0960, 0.0960,\n",
      "         0.0958, 0.0957, 0.0955, 0.0955, 0.0951, 0.0949, 0.0948, 0.0948, 0.0947,\n",
      "         0.0945, 0.0942, 0.0942, 0.0941, 0.0936, 0.0927, 0.0925, 0.0925, 0.0925,\n",
      "         0.0922, 0.0916, 0.0916, 0.0915, 0.0913, 0.0913, 0.0909, 0.0904, 0.0903,\n",
      "         0.0901, 0.0898, 0.0895, 0.0892, 0.0891, 0.0891, 0.0891, 0.0884, 0.0884,\n",
      "         0.0881, 0.0881, 0.0877, 0.0876, 0.0875, 0.0874, 0.0872, 0.0869, 0.0865,\n",
      "         0.0864, 0.0858, 0.0854, 0.0854, 0.0848, 0.0847, 0.0847, 0.0844, 0.0839,\n",
      "         0.0830, 0.0830, 0.0830, 0.0828, 0.0823, 0.0822, 0.0821, 0.0820, 0.0819,\n",
      "         0.0819, 0.0817, 0.0817, 0.0809, 0.0809, 0.0808, 0.0807, 0.0806, 0.0806,\n",
      "         0.0803, 0.0802, 0.0795, 0.0794, 0.0793, 0.0793, 0.0792, 0.0792, 0.0790,\n",
      "         0.0788, 0.0788, 0.0787, 0.0783, 0.0782, 0.0779, 0.0778, 0.0776, 0.0775,\n",
      "         0.0775, 0.0774, 0.0773, 0.0772, 0.0772, 0.0771, 0.0769, 0.0768, 0.0766,\n",
      "         0.0766, 0.0765, 0.0764, 0.0763, 0.0762, 0.0761, 0.0755, 0.0754, 0.0754,\n",
      "         0.0751, 0.0749, 0.0747, 0.0747, 0.0747, 0.0745, 0.0744, 0.0743, 0.0743,\n",
      "         0.0739, 0.0738, 0.0733, 0.0731, 0.0730, 0.0729, 0.0729, 0.0727, 0.0727,\n",
      "         0.0726, 0.0725, 0.0725, 0.0723, 0.0722, 0.0720, 0.0720, 0.0719, 0.0719,\n",
      "         0.0719, 0.0718, 0.0717, 0.0716, 0.0716, 0.0714, 0.0713, 0.0712, 0.0710,\n",
      "         0.0709, 0.0709, 0.0708, 0.0707, 0.0707, 0.0705, 0.0705, 0.0704, 0.0704,\n",
      "         0.0703, 0.0700, 0.0700, 0.0700, 0.0700, 0.0699, 0.0699, 0.0697, 0.0695,\n",
      "         0.0693, 0.0691, 0.0691, 0.0691, 0.0691, 0.0690, 0.0690, 0.0690, 0.0686,\n",
      "         0.0686, 0.0686, 0.0685, 0.0685, 0.0683, 0.0683, 0.0683, 0.0682, 0.0681,\n",
      "         0.0680, 0.0679, 0.0678, 0.0678, 0.0671, 0.0670, 0.0670, 0.0670, 0.0666,\n",
      "         0.0663, 0.0662, 0.0662, 0.0660, 0.0660, 0.0659, 0.0659, 0.0658, 0.0658,\n",
      "         0.0656, 0.0656, 0.0655, 0.0655, 0.0654, 0.0652, 0.0651, 0.0651, 0.0649,\n",
      "         0.0648, 0.0647, 0.0647, 0.0647, 0.0646, 0.0645, 0.0645, 0.0645, 0.0645,\n",
      "         0.0644, 0.0643, 0.0643, 0.0643, 0.0643, 0.0642, 0.0641, 0.0641, 0.0640,\n",
      "         0.0639, 0.0637, 0.0636, 0.0635, 0.0634, 0.0634, 0.0633, 0.0632, 0.0631,\n",
      "         0.0630, 0.0627, 0.0625, 0.0625, 0.0624, 0.0622, 0.0619, 0.0619, 0.0618,\n",
      "         0.0615, 0.0615, 0.0613, 0.0612, 0.0612, 0.0611, 0.0610, 0.0610, 0.0609,\n",
      "         0.0609, 0.0609, 0.0606, 0.0606, 0.0605]], device='cuda:0')\n",
      "tensor([[0.6751, 0.5494, 0.5306, 0.5058, 0.4974, 0.4903, 0.4885, 0.4871, 0.4768,\n",
      "         0.4304, 0.4156, 0.4026, 0.3965, 0.3894, 0.3772, 0.3608, 0.3402, 0.3386,\n",
      "         0.3367, 0.3280, 0.3122, 0.3111, 0.3106, 0.3093, 0.3041, 0.2721, 0.2562,\n",
      "         0.2540, 0.2526, 0.2504, 0.2467, 0.2465, 0.2460, 0.2405, 0.2396, 0.2318,\n",
      "         0.2315, 0.2245, 0.2230, 0.2212, 0.2167, 0.2147, 0.2060, 0.2049, 0.2043,\n",
      "         0.2002, 0.1992, 0.1981, 0.1953, 0.1944, 0.1922, 0.1895, 0.1858, 0.1838,\n",
      "         0.1813, 0.1802, 0.1784, 0.1769, 0.1753, 0.1748, 0.1746, 0.1744, 0.1740,\n",
      "         0.1739, 0.1729, 0.1715, 0.1646, 0.1643, 0.1635, 0.1635, 0.1624, 0.1609,\n",
      "         0.1602, 0.1594, 0.1574, 0.1559, 0.1535, 0.1535, 0.1535, 0.1524, 0.1497,\n",
      "         0.1471, 0.1464, 0.1461, 0.1461, 0.1449, 0.1432, 0.1429, 0.1429, 0.1426,\n",
      "         0.1415, 0.1413, 0.1396, 0.1394, 0.1392, 0.1390, 0.1383, 0.1375, 0.1353,\n",
      "         0.1330, 0.1325, 0.1320, 0.1319, 0.1318, 0.1300, 0.1289, 0.1289, 0.1286,\n",
      "         0.1283, 0.1280, 0.1266, 0.1263, 0.1258, 0.1256, 0.1240, 0.1238, 0.1229,\n",
      "         0.1228, 0.1225, 0.1221, 0.1219, 0.1215, 0.1208, 0.1206, 0.1201, 0.1191,\n",
      "         0.1183, 0.1182, 0.1165, 0.1158, 0.1155, 0.1154, 0.1152, 0.1152, 0.1143,\n",
      "         0.1126, 0.1125, 0.1118, 0.1108, 0.1105, 0.1105, 0.1100, 0.1097, 0.1083,\n",
      "         0.1072, 0.1071, 0.1069, 0.1068, 0.1064, 0.1063, 0.1061, 0.1051, 0.1041,\n",
      "         0.1028, 0.1012, 0.1010, 0.1008, 0.1008, 0.1004, 0.1003, 0.1002, 0.1001,\n",
      "         0.1001, 0.1000, 0.0992, 0.0991, 0.0989, 0.0989, 0.0986, 0.0986, 0.0982,\n",
      "         0.0976, 0.0958, 0.0956, 0.0954, 0.0952, 0.0949, 0.0947, 0.0943, 0.0943,\n",
      "         0.0933, 0.0927, 0.0927, 0.0927, 0.0926, 0.0925, 0.0924, 0.0922, 0.0908,\n",
      "         0.0908, 0.0908, 0.0903, 0.0900, 0.0898, 0.0889, 0.0887, 0.0886, 0.0882,\n",
      "         0.0878, 0.0872, 0.0871, 0.0870, 0.0867, 0.0867, 0.0865, 0.0865, 0.0860,\n",
      "         0.0859, 0.0857, 0.0854, 0.0852, 0.0852, 0.0849, 0.0849, 0.0848, 0.0847,\n",
      "         0.0844, 0.0843, 0.0843, 0.0842, 0.0841, 0.0841, 0.0841, 0.0839, 0.0836,\n",
      "         0.0833, 0.0830, 0.0829, 0.0826, 0.0824, 0.0822, 0.0817, 0.0816, 0.0816,\n",
      "         0.0813, 0.0808, 0.0804, 0.0804, 0.0803, 0.0803, 0.0801, 0.0799, 0.0798,\n",
      "         0.0797, 0.0797, 0.0795, 0.0793, 0.0791, 0.0791, 0.0791, 0.0787, 0.0787,\n",
      "         0.0787, 0.0775, 0.0771, 0.0771, 0.0770, 0.0767, 0.0767, 0.0767, 0.0766,\n",
      "         0.0765, 0.0762, 0.0761, 0.0761, 0.0757, 0.0757, 0.0755, 0.0755, 0.0753,\n",
      "         0.0753, 0.0752, 0.0751, 0.0749, 0.0748, 0.0748, 0.0745, 0.0742, 0.0742,\n",
      "         0.0741, 0.0740, 0.0739, 0.0739, 0.0738, 0.0738, 0.0738, 0.0738, 0.0735,\n",
      "         0.0735, 0.0734, 0.0731, 0.0729, 0.0729, 0.0728, 0.0727, 0.0726, 0.0724,\n",
      "         0.0724, 0.0724, 0.0723, 0.0716, 0.0716, 0.0716, 0.0715, 0.0713, 0.0711,\n",
      "         0.0711, 0.0711, 0.0709, 0.0703, 0.0702, 0.0695, 0.0694, 0.0694, 0.0693,\n",
      "         0.0690, 0.0688, 0.0688, 0.0686, 0.0686, 0.0681, 0.0679, 0.0676, 0.0676,\n",
      "         0.0675, 0.0675, 0.0675, 0.0674, 0.0673, 0.0673, 0.0671, 0.0671, 0.0668,\n",
      "         0.0665, 0.0664, 0.0662, 0.0661, 0.0661, 0.0659, 0.0659, 0.0658, 0.0657,\n",
      "         0.0656, 0.0655, 0.0653, 0.0650, 0.0650, 0.0645, 0.0645, 0.0645, 0.0644,\n",
      "         0.0643, 0.0641, 0.0641, 0.0640, 0.0639, 0.0636, 0.0634, 0.0633, 0.0633,\n",
      "         0.0632, 0.0631, 0.0630, 0.0627, 0.0627, 0.0626, 0.0623, 0.0623, 0.0622,\n",
      "         0.0621, 0.0621, 0.0621, 0.0621, 0.0621, 0.0619, 0.0619, 0.0619, 0.0618,\n",
      "         0.0617, 0.0614, 0.0614, 0.0614, 0.0612, 0.0611, 0.0610, 0.0608, 0.0607,\n",
      "         0.0607, 0.0607, 0.0606, 0.0605, 0.0604, 0.0602, 0.0602, 0.0600, 0.0600,\n",
      "         0.0600, 0.0597, 0.0596, 0.0595, 0.0595, 0.0595, 0.0593, 0.0592, 0.0592,\n",
      "         0.0589, 0.0588, 0.0587, 0.0587, 0.0587, 0.0586, 0.0586, 0.0585, 0.0583,\n",
      "         0.0583, 0.0581, 0.0580, 0.0580, 0.0578, 0.0578, 0.0577, 0.0575, 0.0572,\n",
      "         0.0572, 0.0572, 0.0570, 0.0569, 0.0568, 0.0568, 0.0564, 0.0563, 0.0562,\n",
      "         0.0561, 0.0561, 0.0558, 0.0556, 0.0555, 0.0555, 0.0554, 0.0552, 0.0550,\n",
      "         0.0550, 0.0547, 0.0546, 0.0546, 0.0546, 0.0545, 0.0543, 0.0542, 0.0542,\n",
      "         0.0539, 0.0538, 0.0537, 0.0537, 0.0537, 0.0536, 0.0534, 0.0533, 0.0533,\n",
      "         0.0529, 0.0529, 0.0528, 0.0527, 0.0525, 0.0525, 0.0524, 0.0524, 0.0524,\n",
      "         0.0524, 0.0524, 0.0523, 0.0523, 0.0521, 0.0519, 0.0519, 0.0518, 0.0518,\n",
      "         0.0516, 0.0516, 0.0516, 0.0516, 0.0515, 0.0514, 0.0514, 0.0513, 0.0513,\n",
      "         0.0513, 0.0511, 0.0511, 0.0510, 0.0508, 0.0508, 0.0507, 0.0507, 0.0507,\n",
      "         0.0506, 0.0506, 0.0505, 0.0505, 0.0505]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/workspace/centerformer/work_dirs/partition/engine/inference_with_engine.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f63665f747274227d@ssh-remote%2Bsemo/workspace/centerformer/work_dirs/partition/engine/inference_with_engine.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mprint\u001b[39m(out_dict_list[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f63665f747274227d@ssh-remote%2Bsemo/workspace/centerformer/work_dirs/partition/engine/inference_with_engine.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mprint\u001b[39m(out_dict_list2[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f63665f747274227d@ssh-remote%2Bsemo/workspace/centerformer/work_dirs/partition/engine/inference_with_engine.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f63665f747274227d@ssh-remote%2Bsemo/workspace/centerformer/work_dirs/partition/engine/inference_with_engine.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mbbox_head(out_dict_list)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f63665f747274227d@ssh-remote%2Bsemo/workspace/centerformer/work_dirs/partition/engine/inference_with_engine.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mbbox_head\u001b[39m.\u001b[39mpredict(example, preds, model\u001b[39m.\u001b[39mtest_cfg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from det3d.torchie.apis.train import example_to_device\n",
    "from det3d import torchie\n",
    "\n",
    "prog_bar = torchie.ProgressBar(len(data_loader.dataset) // 1)\n",
    "\n",
    "detections = {}\n",
    "\n",
    "for i, data_batch in enumerate(data_loader):\n",
    "    device = torch.device(\"cuda\")\n",
    "    example = example_to_device(data_batch, device, non_blocking=False)\n",
    "    with torch.no_grad():\n",
    "        example = example_to_device(data_batch, device, non_blocking=False)\n",
    "        del data_batch\n",
    "        with torch.no_grad():\n",
    "            # outputs = model(example, return_loss=False)\n",
    "            reader_output = model.reader(example['points'])    \n",
    "            voxels, coors, shape = reader_output\n",
    "            x, _ = model.backbone(voxels, coors, len(example['points']), shape)\n",
    "            \n",
    "            # Neck\n",
    "            # ct_feat, center_pos_embedding, out_scores, out_labels, out_orders, out_masks = model.neck.find_centers(x)\n",
    "            ct_feat = torch.zeros((1, 3000, 256), dtype=torch.float32, device=x.device)\n",
    "            center_pos_embedding = torch.zeros((1, 3000, 256), dtype=torch.float32, device=x.device)\n",
    "            out_scores = torch.zeros((6, 1, 500), dtype=torch.float32, device=x.device)\n",
    "            out_labels = torch.zeros((6, 1, 500), dtype=torch.int32, device=x.device)\n",
    "            out_orders = torch.zeros((6, 1, 500), dtype=torch.int32, device=x.device)\n",
    "            out_masks = torch.zeros((6, 1, 500), dtype=torch.bool, device=x.device)\n",
    "            IO_tensors = {\n",
    "                \"inputs\" :\n",
    "                {'input_tensor': x},\n",
    "                \"outputs\" :\n",
    "                {'ct_feat': ct_feat, 'center_pos_embedding': center_pos_embedding,\n",
    "                'out_scores': out_scores, 'out_labels': out_labels,\n",
    "                'out_orders': out_orders, 'out_masks': out_masks}\n",
    "            }\n",
    "            run_trt_engine(cf_context, cf_engine, IO_tensors)\n",
    "            \n",
    "            ct_feat = model.neck.poolformer_forward(ct_feat, center_pos_embedding)\n",
    "            \n",
    "            out_dict_list = []\n",
    "            \n",
    "            for idx in range(len(cfg.tasks)):\n",
    "                out_dict = {}\n",
    "                out_dict.update(\n",
    "                    {\n",
    "                        \"scores\": out_scores[idx],\n",
    "                        \"labels\": out_labels[idx],\n",
    "                        \"order\": out_orders[idx],\n",
    "                        \"mask\": out_masks[idx],\n",
    "                        \"ct_feat\": ct_feat[:, :, idx * cfg.test_cfg['obj_num'] : (idx+1) * cfg.test_cfg['obj_num']],\n",
    "                    }\n",
    "                )\n",
    "                out_dict_list.append(out_dict)\n",
    "                \n",
    "            out_dict_list2 = out_dict_lists = model.neck.forward(x)\n",
    "            \n",
    "            print(out_dict_list[0]['scores'])\n",
    "            print(out_dict_list2[0]['scores'])\n",
    "            assert False\n",
    "                \n",
    "            preds = model.bbox_head(out_dict_list)\n",
    "            outputs = model.bbox_head.predict(example, preds, model.test_cfg)\n",
    "            \n",
    "        for output in outputs:\n",
    "            token = output[\"metadata\"][\"token\"]\n",
    "            for k, v in output.items():\n",
    "                if k not in [\n",
    "                    \"metadata\",\n",
    "                ]:\n",
    "                    output[k] = v.to(device=\"cpu\")\n",
    "            detections.update(\n",
    "                {token: output,}\n",
    "            )\n",
    "            \n",
    "            prog_bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "centerformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
