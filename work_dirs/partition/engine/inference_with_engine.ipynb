{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deformable Convolution not built!\n",
      "Deformable Convolution not built!\n",
      "Use center number 500 in inference\n",
      "Use heatmap score threshold 0.03 in inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/centerformer/det3d/core/bbox/geometry.py:149: NumbaDeprecationWarning: The keyword argument 'nopython=False' was supplied. From Numba 0.59.0 the default is being changed to True and use of 'nopython=False' will raise a warning as the argument will have no effect. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit(nopython=False)\n",
      "/data/centerformer/det3d/core/bbox/geometry.py:162: NumbaDeprecationWarning: The keyword argument 'nopython=False' was supplied. From Numba 0.59.0 the default is being changed to True and use of 'nopython=False' will raise a warning as the argument will have no effect. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit(nopython=False)\n",
      "/data/centerformer/det3d/core/bbox/geometry.py:280: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def points_in_convex_polygon_jit(points, polygon, clockwise=True):\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import torch\n",
    "from det3d.torchie import Config\n",
    "from det3d.models import build_detector\n",
    "from det3d.torchie.trainer import load_checkpoint\n",
    "\n",
    "config = \"/workspace/centerformer/configs/nusc/nuscenes_centerformer_poolformer.py\"\n",
    "cfg = Config.fromfile(config)\n",
    "\n",
    "cfg.work_dir = \"/workspace/centerformer/work_dirs/nuscenes_poolformer\"\n",
    "if 'obj_num' in cfg.test_cfg:\n",
    "        cfg.model['neck']['obj_num'] = cfg.test_cfg['obj_num']\n",
    "        print('Use center number {} in inference'.format(cfg.model['neck']['obj_num']))\n",
    "if 'score_threshold' in cfg.test_cfg:\n",
    "    cfg.model['neck']['score_threshold'] = cfg.test_cfg['score_threshold']\n",
    "    print('Use heatmap score threshold {} in inference'.format(cfg.model['neck']['score_threshold']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use HM Bias:  -2.19\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"/workspace/centerformer/work_dirs/nuscenes_poolformer/poolformer.pth\"\n",
    "\n",
    "model = build_detector(cfg.model, train_cfg=None, test_cfg=cfg.test_cfg)\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location=\"cpu\")\n",
    "model.cuda()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no apex\n",
      "No Tensorflow\n",
      "Use Val Set\n",
      "use gt label assigning kernel size  1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from det3d.datasets import build_dataloader, build_dataset\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "os.chdir(\"/workspace/centerformer\")\n",
    "\n",
    "print(\"Use Val Set\")\n",
    "dataset = build_dataset(cfg.data.val)\n",
    "\n",
    "data_loader = build_dataloader(\n",
    "    dataset,\n",
    "    batch_size=cfg.data.samples_per_gpu,\n",
    "    workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "    dist=False,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/13/2023-16:48:42] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\n"
     ]
    }
   ],
   "source": [
    "def load_engine(engine_filepath):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "    with open(engine_filepath, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    return engine\n",
    "\n",
    "centerFinder_engine_path = 'findCenter.trt'\n",
    "cf_engine = load_engine(centerFinder_engine_path)\n",
    "cf_context = cf_engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trt_engine(context, engine, tensors):\n",
    "    bindings = [None]*engine.num_bindings\n",
    "    for idx, binding in enumerate(engine):\n",
    "        tensor_name = engine.get_tensor_name(idx)\n",
    "        if engine.get_tensor_mode(binding)==trt.TensorIOMode.INPUT:\n",
    "            bindings[idx] = tensors['inputs'][tensor_name].data_ptr()\n",
    "            if context.get_tensor_shape(tensor_name):\n",
    "                context.set_input_shape(tensor_name, tensors['inputs'][tensor_name].shape)\n",
    "        else:\n",
    "            bindings[idx] = tensors['outputs'][tensor_name].data_ptr()\n",
    "    context.execute_v2(bindings=bindings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No APEX!\n",
      "[                              ] 0/6019, elapsed: 0s, ETA:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/centerformer/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8610, 0.8600, 0.8393, 0.8083, 0.8044, 0.7641, 0.7413, 0.7288, 0.7048,\n",
      "         0.6847, 0.6831, 0.6785, 0.6444, 0.6397, 0.6353, 0.6312, 0.6230, 0.5880,\n",
      "         0.5813, 0.5762, 0.5750, 0.5687, 0.5622, 0.5600, 0.5405, 0.5021, 0.4977,\n",
      "         0.4964, 0.4836, 0.4738, 0.4396, 0.4358, 0.4336, 0.4208, 0.4134, 0.4042,\n",
      "         0.4001, 0.3994, 0.3968, 0.3764, 0.3758, 0.3660, 0.3656, 0.3572, 0.3466,\n",
      "         0.3457, 0.3433, 0.3372, 0.3363, 0.3348, 0.3094, 0.3040, 0.3037, 0.3031,\n",
      "         0.3031, 0.2965, 0.2842, 0.2781, 0.2743, 0.2723, 0.2705, 0.2680, 0.2657,\n",
      "         0.2657, 0.2646, 0.2628, 0.2578, 0.2462, 0.2393, 0.2391, 0.2384, 0.2338,\n",
      "         0.2336, 0.2317, 0.2279, 0.2277, 0.2254, 0.2220, 0.2208, 0.2204, 0.2197,\n",
      "         0.2185, 0.2176, 0.2067, 0.2008, 0.1964, 0.1943, 0.1932, 0.1913, 0.1866,\n",
      "         0.1856, 0.1832, 0.1827, 0.1806, 0.1770, 0.1770, 0.1758, 0.1746, 0.1738,\n",
      "         0.1730, 0.1728, 0.1724, 0.1720, 0.1719, 0.1707, 0.1667, 0.1661, 0.1639,\n",
      "         0.1632, 0.1630, 0.1620, 0.1604, 0.1601, 0.1589, 0.1580, 0.1579, 0.1559,\n",
      "         0.1554, 0.1543, 0.1531, 0.1510, 0.1506, 0.1505, 0.1505, 0.1504, 0.1489,\n",
      "         0.1488, 0.1466, 0.1456, 0.1446, 0.1444, 0.1444, 0.1438, 0.1426, 0.1421,\n",
      "         0.1405, 0.1383, 0.1381, 0.1381, 0.1373, 0.1369, 0.1366, 0.1356, 0.1355,\n",
      "         0.1354, 0.1347, 0.1341, 0.1340, 0.1339, 0.1334, 0.1333, 0.1325, 0.1321,\n",
      "         0.1309, 0.1306, 0.1303, 0.1301, 0.1293, 0.1291, 0.1289, 0.1288, 0.1284,\n",
      "         0.1283, 0.1281, 0.1273, 0.1269, 0.1267, 0.1263, 0.1247, 0.1237, 0.1229,\n",
      "         0.1221, 0.1212, 0.1203, 0.1202, 0.1201, 0.1199, 0.1199, 0.1197, 0.1196,\n",
      "         0.1193, 0.1187, 0.1177, 0.1176, 0.1175, 0.1174, 0.1171, 0.1162, 0.1159,\n",
      "         0.1135, 0.1135, 0.1131, 0.1128, 0.1125, 0.1121, 0.1117, 0.1110, 0.1104,\n",
      "         0.1103, 0.1100, 0.1085, 0.1082, 0.1082, 0.1076, 0.1076, 0.1059, 0.1057,\n",
      "         0.1048, 0.1043, 0.1043, 0.1043, 0.1037, 0.1033, 0.1030, 0.1030, 0.1024,\n",
      "         0.1015, 0.1010, 0.1010, 0.1006, 0.1002, 0.1000, 0.0999, 0.0999, 0.0998,\n",
      "         0.0992, 0.0991, 0.0990, 0.0985, 0.0984, 0.0984, 0.0981, 0.0978, 0.0976,\n",
      "         0.0976, 0.0974, 0.0974, 0.0973, 0.0963, 0.0963, 0.0963, 0.0960, 0.0960,\n",
      "         0.0958, 0.0957, 0.0955, 0.0955, 0.0951, 0.0949, 0.0948, 0.0948, 0.0947,\n",
      "         0.0945, 0.0942, 0.0942, 0.0941, 0.0936, 0.0927, 0.0925, 0.0925, 0.0925,\n",
      "         0.0922, 0.0916, 0.0916, 0.0915, 0.0913, 0.0913, 0.0909, 0.0904, 0.0903,\n",
      "         0.0901, 0.0898, 0.0895, 0.0892, 0.0891, 0.0891, 0.0891, 0.0884, 0.0884,\n",
      "         0.0881, 0.0881, 0.0877, 0.0876, 0.0875, 0.0874, 0.0872, 0.0869, 0.0865,\n",
      "         0.0864, 0.0858, 0.0854, 0.0854, 0.0848, 0.0847, 0.0847, 0.0844, 0.0839,\n",
      "         0.0830, 0.0830, 0.0830, 0.0828, 0.0823, 0.0822, 0.0821, 0.0820, 0.0819,\n",
      "         0.0819, 0.0817, 0.0817, 0.0809, 0.0809, 0.0808, 0.0807, 0.0806, 0.0806,\n",
      "         0.0803, 0.0802, 0.0795, 0.0794, 0.0793, 0.0793, 0.0792, 0.0792, 0.0790,\n",
      "         0.0788, 0.0788, 0.0787, 0.0783, 0.0782, 0.0779, 0.0778, 0.0776, 0.0775,\n",
      "         0.0775, 0.0774, 0.0773, 0.0772, 0.0772, 0.0771, 0.0769, 0.0768, 0.0766,\n",
      "         0.0766, 0.0765, 0.0764, 0.0763, 0.0762, 0.0761, 0.0755, 0.0754, 0.0754,\n",
      "         0.0751, 0.0749, 0.0747, 0.0747, 0.0747, 0.0745, 0.0744, 0.0743, 0.0743,\n",
      "         0.0739, 0.0738, 0.0733, 0.0731, 0.0730, 0.0729, 0.0729, 0.0727, 0.0727,\n",
      "         0.0726, 0.0725, 0.0725, 0.0723, 0.0722, 0.0720, 0.0720, 0.0719, 0.0719,\n",
      "         0.0719, 0.0718, 0.0717, 0.0716, 0.0716, 0.0714, 0.0713, 0.0712, 0.0710,\n",
      "         0.0709, 0.0709, 0.0708, 0.0707, 0.0707, 0.0705, 0.0705, 0.0704, 0.0704,\n",
      "         0.0703, 0.0700, 0.0700, 0.0700, 0.0700, 0.0699, 0.0699, 0.0697, 0.0695,\n",
      "         0.0693, 0.0691, 0.0691, 0.0691, 0.0691, 0.0690, 0.0690, 0.0690, 0.0686,\n",
      "         0.0686, 0.0686, 0.0685, 0.0685, 0.0683, 0.0683, 0.0683, 0.0682, 0.0681,\n",
      "         0.0680, 0.0679, 0.0678, 0.0678, 0.0671, 0.0670, 0.0670, 0.0670, 0.0666,\n",
      "         0.0663, 0.0662, 0.0662, 0.0660, 0.0660, 0.0659, 0.0659, 0.0658, 0.0658,\n",
      "         0.0656, 0.0656, 0.0655, 0.0655, 0.0654, 0.0652, 0.0651, 0.0651, 0.0649,\n",
      "         0.0648, 0.0647, 0.0647, 0.0647, 0.0646, 0.0645, 0.0645, 0.0645, 0.0645,\n",
      "         0.0644, 0.0643, 0.0643, 0.0643, 0.0643, 0.0642, 0.0641, 0.0641, 0.0640,\n",
      "         0.0639, 0.0637, 0.0636, 0.0635, 0.0634, 0.0634, 0.0633, 0.0632, 0.0631,\n",
      "         0.0630, 0.0627, 0.0625, 0.0625, 0.0624, 0.0622, 0.0619, 0.0619, 0.0618,\n",
      "         0.0615, 0.0615, 0.0613, 0.0612, 0.0612, 0.0611, 0.0610, 0.0610, 0.0609,\n",
      "         0.0609, 0.0609, 0.0606, 0.0606, 0.0605]], device='cuda:0')\n",
      "tensor([[0.7592, 0.7388, 0.4794, 0.4439, 0.4069, 0.3835, 0.3662, 0.3082, 0.2274,\n",
      "         0.1737, 0.1364, 0.1288, 0.1115, 0.0699, 0.0648, 0.0638, 0.0619, 0.0560,\n",
      "         0.0560, 0.0546, 0.0545, 0.0539, 0.0534, 0.0528, 0.0526, 0.0524, 0.0507,\n",
      "         0.0506, 0.0506, 0.0505, 0.0499, 0.0486, 0.0486, 0.0477, 0.0474, 0.0471,\n",
      "         0.0466, 0.0459, 0.0453, 0.0448, 0.0445, 0.0440, 0.0428, 0.0427, 0.0425,\n",
      "         0.0424, 0.0422, 0.0420, 0.0412, 0.0408, 0.0405, 0.0405, 0.0404, 0.0400,\n",
      "         0.0399, 0.0398, 0.0395, 0.0394, 0.0394, 0.0385, 0.0381, 0.0378, 0.0376,\n",
      "         0.0374, 0.0374, 0.0373, 0.0372, 0.0369, 0.0368, 0.0367, 0.0364, 0.0363,\n",
      "         0.0360, 0.0359, 0.0359, 0.0358, 0.0355, 0.0350, 0.0350, 0.0349, 0.0345,\n",
      "         0.0343, 0.0342, 0.0342, 0.0339, 0.0338, 0.0338, 0.0336, 0.0335, 0.0334,\n",
      "         0.0334, 0.0330, 0.0328, 0.0328, 0.0326, 0.0325, 0.0322, 0.0321, 0.0321,\n",
      "         0.0320, 0.0318, 0.0316, 0.0316, 0.0316, 0.0316, 0.0312, 0.0310, 0.0309,\n",
      "         0.0307, 0.0307, 0.0306, 0.0306, 0.0306, 0.0306, 0.0304, 0.0304, 0.0303,\n",
      "         0.0302, 0.0302, 0.0302, 0.0301, 0.0300, 0.0300, 0.0299, 0.0299, 0.0299,\n",
      "         0.0298, 0.0297, 0.0296, 0.0296, 0.0295, 0.0295, 0.0295, 0.0294, 0.0293,\n",
      "         0.0292, 0.0292, 0.0291, 0.0290, 0.0290, 0.0289, 0.0288, 0.0288, 0.0288,\n",
      "         0.0285, 0.0285, 0.0284, 0.0284, 0.0283, 0.0283, 0.0283, 0.0282, 0.0282,\n",
      "         0.0281, 0.0280, 0.0280, 0.0279, 0.0279, 0.0279, 0.0278, 0.0277, 0.0277,\n",
      "         0.0277, 0.0277, 0.0276, 0.0276, 0.0275, 0.0275, 0.0274, 0.0274, 0.0274,\n",
      "         0.0273, 0.0272, 0.0272, 0.0272, 0.0271, 0.0271, 0.0271, 0.0270, 0.0270,\n",
      "         0.0269, 0.0269, 0.0268, 0.0268, 0.0267, 0.0267, 0.0267, 0.0266, 0.0265,\n",
      "         0.0264, 0.0264, 0.0264, 0.0264, 0.0264, 0.0263, 0.0262, 0.0261, 0.0261,\n",
      "         0.0260, 0.0260, 0.0259, 0.0258, 0.0257, 0.0257, 0.0256, 0.0256, 0.0256,\n",
      "         0.0256, 0.0256, 0.0255, 0.0255, 0.0255, 0.0255, 0.0254, 0.0254, 0.0254,\n",
      "         0.0253, 0.0253, 0.0253, 0.0253, 0.0253, 0.0252, 0.0252, 0.0252, 0.0252,\n",
      "         0.0252, 0.0251, 0.0251, 0.0251, 0.0251, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0249, 0.0248, 0.0248, 0.0248, 0.0247,\n",
      "         0.0247, 0.0247, 0.0247, 0.0245, 0.0245, 0.0244, 0.0244, 0.0243, 0.0243,\n",
      "         0.0242, 0.0241, 0.0241, 0.0240, 0.0240, 0.0240, 0.0239, 0.0239, 0.0239,\n",
      "         0.0239, 0.0239, 0.0238, 0.0237, 0.0237, 0.0237, 0.0237, 0.0236, 0.0236,\n",
      "         0.0236, 0.0236, 0.0236, 0.0236, 0.0236, 0.0235, 0.0235, 0.0234, 0.0234,\n",
      "         0.0234, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0232, 0.0232, 0.0232,\n",
      "         0.0232, 0.0232, 0.0232, 0.0232, 0.0231, 0.0231, 0.0231, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0229, 0.0229, 0.0229, 0.0229, 0.0229,\n",
      "         0.0228, 0.0228, 0.0228, 0.0228, 0.0228, 0.0228, 0.0227, 0.0227, 0.0227,\n",
      "         0.0227, 0.0227, 0.0226, 0.0226, 0.0226, 0.0226, 0.0226, 0.0225, 0.0225,\n",
      "         0.0225, 0.0225, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224,\n",
      "         0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0222, 0.0222, 0.0222, 0.0222,\n",
      "         0.0222, 0.0222, 0.0221, 0.0221, 0.0221, 0.0221, 0.0221, 0.0221, 0.0221,\n",
      "         0.0221, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0219, 0.0219, 0.0219,\n",
      "         0.0219, 0.0219, 0.0219, 0.0218, 0.0218, 0.0218, 0.0218, 0.0217, 0.0217,\n",
      "         0.0217, 0.0217, 0.0217, 0.0217, 0.0216, 0.0215, 0.0215, 0.0215, 0.0215,\n",
      "         0.0215, 0.0214, 0.0214, 0.0214, 0.0213, 0.0213, 0.0213, 0.0213, 0.0213,\n",
      "         0.0213, 0.0213, 0.0213, 0.0212, 0.0212, 0.0212, 0.0212, 0.0211, 0.0211,\n",
      "         0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0209, 0.0209, 0.0209, 0.0209,\n",
      "         0.0209, 0.0208, 0.0208, 0.0208, 0.0208, 0.0208, 0.0208, 0.0208, 0.0208,\n",
      "         0.0208, 0.0208, 0.0208, 0.0207, 0.0207, 0.0206, 0.0206, 0.0206, 0.0206,\n",
      "         0.0206, 0.0206, 0.0206, 0.0206, 0.0206, 0.0206, 0.0206, 0.0206, 0.0206,\n",
      "         0.0205, 0.0205, 0.0205, 0.0204, 0.0204, 0.0204, 0.0204, 0.0204, 0.0204,\n",
      "         0.0204, 0.0204, 0.0204, 0.0203, 0.0203, 0.0203, 0.0203, 0.0203, 0.0202,\n",
      "         0.0202, 0.0202, 0.0202, 0.0202, 0.0202, 0.0202, 0.0202, 0.0202, 0.0202,\n",
      "         0.0202, 0.0201, 0.0201, 0.0201, 0.0201, 0.0201, 0.0201, 0.0201, 0.0201,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0199, 0.0199,\n",
      "         0.0199, 0.0199, 0.0199, 0.0199, 0.0199, 0.0198, 0.0198, 0.0198, 0.0198,\n",
      "         0.0198, 0.0198, 0.0197, 0.0197, 0.0197]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/workspace/centerformer/work_dirs/partition/engine/inference_with_engine.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f63665f747274227d@ssh-remote%2Bsemo/workspace/centerformer/work_dirs/partition/engine/inference_with_engine.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mprint\u001b[39m(out_dict_list[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f63665f747274227d@ssh-remote%2Bsemo/workspace/centerformer/work_dirs/partition/engine/inference_with_engine.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mprint\u001b[39m(out_dict_list2[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f63665f747274227d@ssh-remote%2Bsemo/workspace/centerformer/work_dirs/partition/engine/inference_with_engine.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f63665f747274227d@ssh-remote%2Bsemo/workspace/centerformer/work_dirs/partition/engine/inference_with_engine.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mbbox_head(out_dict_list)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f63665f747274227d@ssh-remote%2Bsemo/workspace/centerformer/work_dirs/partition/engine/inference_with_engine.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mbbox_head\u001b[39m.\u001b[39mpredict(example, preds, model\u001b[39m.\u001b[39mtest_cfg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from det3d.torchie.apis.train import example_to_device\n",
    "from det3d import torchie\n",
    "\n",
    "prog_bar = torchie.ProgressBar(len(data_loader.dataset) // 1)\n",
    "\n",
    "detections = {}\n",
    "\n",
    "for i, data_batch in enumerate(data_loader):\n",
    "    device = torch.device(\"cuda\")\n",
    "    example = example_to_device(data_batch, device, non_blocking=False)\n",
    "    with torch.no_grad():\n",
    "        example = example_to_device(data_batch, device, non_blocking=False)\n",
    "        del data_batch\n",
    "        with torch.no_grad():\n",
    "            # outputs = model(example, return_loss=False)\n",
    "            reader_output = model.reader(example['points'])    \n",
    "            voxels, coors, shape = reader_output\n",
    "            x, _ = model.backbone(voxels, coors, len(example['points']), shape)\n",
    "            \n",
    "            # Neck\n",
    "            # ct_feat, center_pos_embedding, out_scores, out_labels, out_orders, out_masks = model.neck.find_centers(x)\n",
    "            ct_feat = torch.zeros((1, 3000, 256), dtype=torch.float32, device=x.device)\n",
    "            center_pos_embedding = torch.zeros((1, 3000, 256), dtype=torch.float32, device=x.device)\n",
    "            out_scores = torch.zeros((6, 1, 500), dtype=torch.float32, device=x.device)\n",
    "            out_labels = torch.zeros((6, 1, 500), dtype=torch.int32, device=x.device)\n",
    "            out_orders = torch.zeros((6, 1, 500), dtype=torch.int32, device=x.device)\n",
    "            out_masks = torch.zeros((6, 1, 500), dtype=torch.bool, device=x.device)\n",
    "            IO_tensors = {\n",
    "                \"inputs\" :\n",
    "                {'input_tensor': x},\n",
    "                \"outputs\" :\n",
    "                {'ct_feat': ct_feat, 'center_pos_embedding': center_pos_embedding,\n",
    "                'out_scores': out_scores, 'out_labels': out_labels,\n",
    "                'out_orders': out_orders, 'out_masks': out_masks}\n",
    "            }\n",
    "            run_trt_engine(cf_context, cf_engine, IO_tensors)\n",
    "            \n",
    "            ct_feat = model.neck.poolformer_forward(ct_feat, center_pos_embedding)\n",
    "            \n",
    "            out_dict_list = []\n",
    "            \n",
    "            for idx in range(len(cfg.tasks)):\n",
    "                out_dict = {}\n",
    "                out_dict.update(\n",
    "                    {\n",
    "                        \"scores\": out_scores[idx],\n",
    "                        \"labels\": out_labels[idx],\n",
    "                        \"order\": out_orders[idx],\n",
    "                        \"mask\": out_masks[idx],\n",
    "                        \"ct_feat\": ct_feat[:, :, idx * cfg.test_cfg['obj_num'] : (idx+1) * cfg.test_cfg['obj_num']],\n",
    "                    }\n",
    "                )\n",
    "                out_dict_list.append(out_dict)\n",
    "                \n",
    "            out_dict_list2 = out_dict_lists = model.neck.forward(x)\n",
    "            \n",
    "            print(out_dict_list[0]['scores'])\n",
    "            print(out_dict_list2[0]['scores'])\n",
    "            assert False\n",
    "                \n",
    "            preds = model.bbox_head(out_dict_list)\n",
    "            outputs = model.bbox_head.predict(example, preds, model.test_cfg)\n",
    "            \n",
    "        for output in outputs:\n",
    "            token = output[\"metadata\"][\"token\"]\n",
    "            for k, v in output.items():\n",
    "                if k not in [\n",
    "                    \"metadata\",\n",
    "                ]:\n",
    "                    output[k] = v.to(device=\"cpu\")\n",
    "            detections.update(\n",
    "                {token: output,}\n",
    "            )\n",
    "            \n",
    "            prog_bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "centerformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
