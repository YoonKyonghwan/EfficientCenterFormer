{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from det3d.torchie import Config\n",
    "\n",
    "import pickle\n",
    "\n",
    "config = \"/workspace/centerformer/configs/nusc/nuscenes_centerformer_poolformer.py\"\n",
    "\n",
    "cfg = Config.fromfile(config)\n",
    "FINDCENTER_GEN_ONNX = True\n",
    "POOLFORMER_GEN_ONNX = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deformable Convolution not built!\n",
      "Deformable Convolution not built!\n",
      "Use HM Bias:  -2.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/centerformer/det3d/core/bbox/geometry.py:149: NumbaDeprecationWarning: The keyword argument 'nopython=False' was supplied. From Numba 0.59.0 the default is being changed to True and use of 'nopython=False' will raise a warning as the argument will have no effect. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit(nopython=False)\n",
      "/data/centerformer/det3d/core/bbox/geometry.py:162: NumbaDeprecationWarning: The keyword argument 'nopython=False' was supplied. From Numba 0.59.0 the default is being changed to True and use of 'nopython=False' will raise a warning as the argument will have no effect. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit(nopython=False)\n",
      "/data/centerformer/det3d/core/bbox/geometry.py:280: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def points_in_convex_polygon_jit(points, polygon, clockwise=True):\n"
     ]
    }
   ],
   "source": [
    "from det3d.models import build_detector\n",
    "from det3d.torchie.trainer import load_checkpoint\n",
    "\n",
    "checkpoint_path = \"/workspace/centerformer/work_dirs/nuscenes_poolformer/poolformer.pth\"\n",
    "\n",
    "model = build_detector(cfg.model, train_cfg=None, test_cfg=cfg.test_cfg)\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location=\"cpu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CenterFinder(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(CenterFinder, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.model.neck(x)\n",
    "        # preds = self.model.bbox_head(x)\n",
    "        # return preds\n",
    "        return self.model.neck.find_centers(x) # pos_features, out_dict_list, ct_feat \n",
    "    \n",
    "centerFinder = CenterFinder(model)\n",
    "centerFinder.cuda()\n",
    "centerFinder.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open(\"/workspace/centerformer/work_dirs/partition/sample_data/x.pkl\", 'wb') as handle:\n",
    "#     pickle.dump(x, handle)\n",
    "# with open(\"/workspace/centerformer/work_dirs/partition/sample_data/example.pkl\", 'wb') as handle:\n",
    "#     pickle.dump(example, handle)\n",
    "\n",
    "pickle_dir = \"/workspace/centerformer/work_dirs/partition/sample_data/\"\n",
    "\n",
    "with open(pickle_dir + \"findcenter_input.pkl\", 'rb') as handle:\n",
    "    x = pickle.load(handle)\n",
    "# with open(pickle_dir + \"example.pkl\", 'rb') as handle:\n",
    "#     example = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/centerformer/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    ct_feat, center_pos_embedding, out_scores, out_labels, out_orders, out_masks = centerFinder(x)\n",
    "    \n",
    "with open(pickle_dir + \"findcenter_output1.pkl\", 'rb') as handle:\n",
    "    output1 = pickle.load(handle)\n",
    "with open(pickle_dir + \"findcenter_output2.pkl\", 'rb') as handle:\n",
    "    output2 = pickle.load(handle)\n",
    "with open(pickle_dir + \"findcenter_output3.pkl\", 'rb') as handle:\n",
    "    output3 = pickle.load(handle)\n",
    "    \n",
    "print((output1 == ct_feat).all())\n",
    "print((output2 == center_pos_embedding).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/centerformer/det3d/models/necks/rpn_transformer_multitask.py:932: TracerWarning: Converting a tensor to a NumPy array might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  scores = scores.detach().cpu().numpy()\n",
      "/data/centerformer/det3d/models/necks/rpn_transformer_multitask.py:934: TracerWarning: torch.from_numpy results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  order = torch.from_numpy(order).to(labels.device)\n",
      "/data/centerformer/det3d/models/necks/rpn_transformer_multitask.py:935: TracerWarning: torch.from_numpy results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  scores = torch.from_numpy(scores).to(labels.device)\n",
      "/root/anaconda3/envs/centerformer/lib/python3.9/site-packages/numpy/core/numeric.py:1779: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  idx = arange(dim, dtype=dtype).reshape(\n",
      "/root/anaconda3/envs/centerformer/lib/python3.9/site-packages/numpy/core/numeric.py:1779: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  idx = arange(dim, dtype=dtype).reshape(\n",
      "/data/centerformer/det3d/models/necks/rpn_transformer_multitask.py:947: TracerWarning: torch.from_numpy results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  self.batch_id = torch.from_numpy(np.indices((batch, self.obj_num * len(self.tasks)))[0]).to(labels)\n",
      "/data/centerformer/det3d/models/necks/rpn_transformer_multitask.py:990: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  row_tensor = torch.tensor(tensor_list, device=to_device, dtype=torch.float32)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "/root/anaconda3/envs/centerformer/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:2762: UserWarning: Exporting aten::index operator of advanced indexing in opset 11 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  warnings.warn(\"Exporting aten::index operator of advanced indexing in opset \" +\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;14m[I] RUNNING | Command: /root/anaconda3/envs/centerformer/bin/polygraphy surgeon sanitize findCenter.onnx --fold-constants --output findCenter_folded.onnx\u001b[0m\n",
      "[I] Loading model: /data/centerformer/work_dirs/partition/onnx/findCenter.onnx\n",
      "[I] Original Model:\n",
      "    Name: torch-jit-export | ONNX Opset: 11\n",
      "    \n",
      "    ---- 1 Graph Input(s) ----\n",
      "    {input_tensor [dtype=float32, shape=(1, 256, 180, 180)]}\n",
      "    \n",
      "    ---- 6 Graph Output(s) ----\n",
      "    {ct_feat [dtype=float32, shape=(1, 3000, 256)],\n",
      "     center_pos_embedding [dtype=float32, shape=(1, 3000, 256)],\n",
      "     out_scores [dtype=float32, shape=(6, 1, 500)],\n",
      "     out_labels [dtype=int64, shape=(6, 1, 500)],\n",
      "     out_orders [dtype=int64, shape=(6, 1, 500)],\n",
      "     out_masks [dtype=bool, shape=(6, 1, 500)]}\n",
      "    \n",
      "    ---- 132 Initializer(s) ----\n",
      "    \n",
      "    ---- 623 Node(s) ----\n",
      "    \n",
      "\u001b[38;5;14m[I] Folding Constants | Pass 1\u001b[0m\n",
      "2023-12-13 17:02:04.587154121 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_580\n",
      "2023-12-13 17:02:04.587169209 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_126\n",
      "2023-12-13 17:02:04.587175574 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_123\n",
      "2023-12-13 17:02:04.587180451 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_117\n",
      "2023-12-13 17:02:04.587185583 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_522\n",
      "2023-12-13 17:02:04.587188104 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_521\n",
      "2023-12-13 17:02:04.587190524 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_447\n",
      "2023-12-13 17:02:04.587192842 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_446\n",
      "2023-12-13 17:02:04.587195260 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_372\n",
      "2023-12-13 17:02:04.587197650 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_371\n",
      "2023-12-13 17:02:04.587200359 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_297\n",
      "2023-12-13 17:02:04.587202531 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_296\n",
      "2023-12-13 17:02:04.587204861 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_222\n",
      "2023-12-13 17:02:04.587208888 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_221\n",
      "2023-12-13 17:02:04.587211842 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_120\n",
      "2023-12-13 17:02:04.587214584 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_147\n",
      "2023-12-13 17:02:04.587216855 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node Unsqueeze_146\n",
      "\u001b[38;5;11m[W] It looks like this model contains foldable nodes that produce large outputs.\n",
      "In order to avoid bloating the model, you may want to set a constant-folding size threshold.\n",
      "Note: Large tensors and their corresponding sizes were: {'1394': '2 MiB', 'center_pos_embedding': '2 MiB'}\u001b[0m\n",
      "\u001b[38;5;10m[I]     Total Nodes | Original:   623, After Folding:   152 |   471 Nodes Folded\u001b[0m\n",
      "\u001b[38;5;14m[I] Folding Constants | Pass 2\u001b[0m\n",
      "\u001b[38;5;10m[I]     Total Nodes | Original:   152, After Folding:   152 |     0 Nodes Folded\u001b[0m\n",
      "[I] Saving ONNX model to: findCenter_folded.onnx\n",
      "[I] New Model:\n",
      "    Name: torch-jit-export | ONNX Opset: 11\n",
      "    \n",
      "    ---- 1 Graph Input(s) ----\n",
      "    {input_tensor [dtype=float32, shape=(1, 256, 180, 180)]}\n",
      "    \n",
      "    ---- 6 Graph Output(s) ----\n",
      "    {ct_feat [dtype=float32, shape=(1, 3000, 256)],\n",
      "     center_pos_embedding [dtype=float32, shape=(1, 3000, 256)],\n",
      "     out_scores [dtype=float32, shape=(6, 1, 500)],\n",
      "     out_labels [dtype=int64, shape=(6, 1, 500)],\n",
      "     out_orders [dtype=int64, shape=(6, 1, 500)],\n",
      "     out_masks [dtype=bool, shape=(6, 1, 500)]}\n",
      "    \n",
      "    ---- 112 Initializer(s) ----\n",
      "    \n",
      "    ---- 152 Node(s) ----\n",
      "    \n",
      "\u001b[38;5;10m[I] PASSED | Runtime: 0.760s | Command: /root/anaconda3/envs/centerformer/bin/polygraphy surgeon sanitize findCenter.onnx --fold-constants --output findCenter_folded.onnx\u001b[0m\n",
      "gen findCenter.onnx success!\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "if FINDCENTER_GEN_ONNX:\n",
    "    model_name = \"findCenter.onnx\"\n",
    "    dummy_input=torch.randn(x.shape).cuda()\n",
    "    torch.onnx.export(centerFinder, dummy_input, model_name,\n",
    "                input_names=['input_tensor'], \n",
    "                output_names=['ct_feat', 'center_pos_embedding', 'out_scores', 'out_labels', 'out_orders', 'out_masks'],\n",
    "                export_params=True, opset_version=11)\n",
    "    \n",
    "    # !export POLYGRAPHY_AUTOINSTALL_DEPS=1\n",
    "    !polygraphy surgeon sanitize findCenter.onnx --fold-constants --output findCenter_folded.onnx\n",
    "\n",
    "    onnx.checker.check_model(onnx.load(\"findCenter_folded.onnx\"))\n",
    "    print(\"gen findCenter.onnx success!\")\n",
    "else:\n",
    "    print(\"pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 180, 180])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ct_feat = centerFinder.model.neck.poolformer_forward(ct_feat, center_pos_embedding)\n",
    "            \n",
    "out_dict_list = []\n",
    "num_tasks = len(centerFinder.model.neck.tasks)\n",
    "obj_num = centerFinder.model.neck.obj_num\n",
    "for idx in range(num_tasks):\n",
    "    out_dict = {}\n",
    "    out_dict.update(\n",
    "        {\n",
    "            \"scores\": out_scores[idx],\n",
    "            \"labels\": out_labels[idx],\n",
    "            \"order\": out_orders[idx],\n",
    "            \"mask\": out_masks[idx],\n",
    "            \"ct_feat\": ct_feat[:, :, idx * obj_num : (idx+1) * obj_num],\n",
    "        }\n",
    "    )\n",
    "    out_dict_list.append(out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_dir + \"neck_output.pkl\", 'rb') as handle:\n",
    "    output_poolformer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['scores', 'labels', 'order', 'mask', 'ct_feat'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict_list[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "scores tensor(True, device='cuda:0')\n",
      "labels tensor(True, device='cuda:0')\n",
      "orders tensor(True, device='cuda:0')\n",
      "masks tensor(False, device='cuda:0')\n",
      "ct_feat tensor(True, device='cuda:0')\n",
      "1\n",
      "scores tensor(True, device='cuda:0')\n",
      "labels tensor(True, device='cuda:0')\n",
      "orders tensor(True, device='cuda:0')\n",
      "masks tensor(False, device='cuda:0')\n",
      "ct_feat tensor(True, device='cuda:0')\n",
      "2\n",
      "scores tensor(True, device='cuda:0')\n",
      "labels tensor(True, device='cuda:0')\n",
      "orders tensor(True, device='cuda:0')\n",
      "masks tensor(False, device='cuda:0')\n",
      "ct_feat tensor(True, device='cuda:0')\n",
      "3\n",
      "scores tensor(True, device='cuda:0')\n",
      "labels tensor(True, device='cuda:0')\n",
      "orders tensor(True, device='cuda:0')\n",
      "masks tensor(False, device='cuda:0')\n",
      "ct_feat tensor(True, device='cuda:0')\n",
      "4\n",
      "scores tensor(True, device='cuda:0')\n",
      "labels tensor(True, device='cuda:0')\n",
      "orders tensor(True, device='cuda:0')\n",
      "masks tensor(False, device='cuda:0')\n",
      "ct_feat tensor(True, device='cuda:0')\n",
      "5\n",
      "scores tensor(True, device='cuda:0')\n",
      "labels tensor(True, device='cuda:0')\n",
      "orders tensor(True, device='cuda:0')\n",
      "masks tensor(False, device='cuda:0')\n",
      "ct_feat tensor(True, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(out_dict_list)):\n",
    "    print(i)\n",
    "    print('scores', (output_poolformer[i]['scores']==out_dict_list[i]['scores']).all())\n",
    "    print('labels', (output_poolformer[i]['labels']==out_dict_list[i]['labels']).all())\n",
    "    print('orders', (output_poolformer[i]['order']==out_dict_list[i]['order']).all())\n",
    "    print('masks', (output_poolformer[i]['mask']==out_dict_list[i]['mask']).all())\n",
    "    print('ct_feat', (output_poolformer[i]['ct_feat']==out_dict_list[i]['ct_feat']).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output_poolformer[i]['mask']==out_dict_list[i]['mask'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "centerformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
