{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from det3d.torchie import Config\n",
    "\n",
    "import pickle\n",
    "\n",
    "config = \"/workspace/centerformer/configs/nusc/nuscenes_centerformer_poolformer.py\"\n",
    "\n",
    "cfg = Config.fromfile(config)\n",
    "FINDCENTER_GEN_ONNX = True\n",
    "POOLFORMER_GEN_ONNX = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/centerformer/det3d/core/bbox/geometry.py:149: NumbaDeprecationWarning: The keyword argument 'nopython=False' was supplied. From Numba 0.59.0 the default is being changed to True and use of 'nopython=False' will raise a warning as the argument will have no effect. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit(nopython=False)\n",
      "/data/centerformer/det3d/core/bbox/geometry.py:162: NumbaDeprecationWarning: The keyword argument 'nopython=False' was supplied. From Numba 0.59.0 the default is being changed to True and use of 'nopython=False' will raise a warning as the argument will have no effect. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit(nopython=False)\n",
      "/data/centerformer/det3d/core/bbox/geometry.py:280: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def points_in_convex_polygon_jit(points, polygon, clockwise=True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deformable Convolution not built!\n",
      "Deformable Convolution not built!\n",
      "[12/14/2023-07:08:44] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\n",
      "Use HM Bias:  -2.19\n"
     ]
    }
   ],
   "source": [
    "from det3d.models import build_detector\n",
    "from det3d.torchie.trainer import load_checkpoint\n",
    "\n",
    "checkpoint_path = \"/workspace/centerformer/work_dirs/nuscenes_poolformer/poolformer.pth\"\n",
    "\n",
    "model = build_detector(cfg.model, train_cfg=None, test_cfg=cfg.test_cfg)\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location=\"cpu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CenterFinder(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(CenterFinder, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.model.neck(x)\n",
    "        # preds = self.model.bbox_head(x)\n",
    "        # return preds\n",
    "        return self.model.neck.find_centers(x) # pos_features, out_dict_list, ct_feat \n",
    "    \n",
    "centerFinder = CenterFinder(model)\n",
    "# centerFinder.cuda()\n",
    "centerFinder.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/centerformer/det3d/models/necks/rpn_transformer_multitask.py:940: TracerWarning: Converting a tensor to a NumPy array might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  scores = scores.detach().cpu().numpy()\n",
      "/data/centerformer/det3d/models/necks/rpn_transformer_multitask.py:942: TracerWarning: torch.from_numpy results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  order = torch.from_numpy(order).to(labels.device)\n",
      "/data/centerformer/det3d/models/necks/rpn_transformer_multitask.py:943: TracerWarning: torch.from_numpy results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  scores = torch.from_numpy(scores).to(labels.device)\n",
      "/root/anaconda3/envs/trt/lib/python3.9/site-packages/numpy/core/numeric.py:1779: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  idx = arange(dim, dtype=dtype).reshape(\n",
      "/root/anaconda3/envs/trt/lib/python3.9/site-packages/numpy/core/numeric.py:1779: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  idx = arange(dim, dtype=dtype).reshape(\n",
      "/data/centerformer/det3d/models/necks/rpn_transformer_multitask.py:955: TracerWarning: torch.from_numpy results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  self.batch_id = torch.from_numpy(np.indices((batch, self.obj_num * len(self.tasks)))[0]).to(labels)\n",
      "/data/centerformer/det3d/models/necks/rpn_transformer_multitask.py:998: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  row_tensor = torch.tensor(tensor_list, device=to_device, dtype=torch.float32)\n",
      "/root/anaconda3/envs/trt/lib/python3.9/site-packages/torch/onnx/_internal/jit_utils.py:306: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/root/anaconda3/envs/trt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:5589: UserWarning: Exporting aten::index operator of advanced indexing in opset 14 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/trt/lib/python3.9/site-packages/torch/onnx/utils.py:689: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/root/anaconda3/envs/trt/lib/python3.9/site-packages/torch/onnx/utils.py:1186: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[W] 'colored' module is not installed, will not use colors when logging. To enable colors, please install the 'colored' module: python3 -m pip install colored\n",
      "[I] RUNNING | Command: /usr/local/bin/polygraphy surgeon sanitize findCenter.onnx --fold-constants --output findCenter_folded.onnx\n",
      "[I] Inferring shapes in the model with `onnxruntime.tools.symbolic_shape_infer`.\n",
      "    Note: To force Polygraphy to use `onnx.shape_inference` instead, set `allow_onnxruntime=False` or use the `--no-onnxruntime-shape-inference` command-line option.\n",
      "[I] Loading model: /data/centerformer/work_dirs/partition/onnx/findCenter.onnx\n",
      "[I] Original Model:\n",
      "    Name: torch_jit | ONNX Opset: 14\n",
      "    \n",
      "    ---- 1 Graph Input(s) ----\n",
      "    {input_tensor [dtype=float32, shape=(1, 256, 180, 180)]}\n",
      "    \n",
      "    ---- 6 Graph Output(s) ----\n",
      "    {ct_feat [dtype=float32, shape=(1, 3000, 256)],\n",
      "     center_pos_embedding [dtype=float32, shape=(1, 3000, 256)],\n",
      "     out_scores [dtype=float32, shape=(6, 1, 500)],\n",
      "     out_labels [dtype=int64, shape=(6, 1, 500)],\n",
      "     out_orders [dtype=int64, shape=(6, 1, 500)],\n",
      "     out_masks [dtype=bool, shape=(6, 1, 500)]}\n",
      "    \n",
      "    ---- 71 Initializer(s) ----\n",
      "    \n",
      "    ---- 697 Node(s) ----\n",
      "    \n",
      "[I] Folding Constants | Pass 1\n",
      "2023-12-14 07:08:48.043786735 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze_22\n",
      "2023-12-14 07:08:48.043801004 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze_3\n",
      "2023-12-14 07:08:48.043808262 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze_2\n",
      "2023-12-14 07:08:48.043813810 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze\n",
      "2023-12-14 07:08:48.043819160 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze_20\n",
      "2023-12-14 07:08:48.043822176 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze_19\n",
      "2023-12-14 07:08:48.043825212 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze_17\n",
      "2023-12-14 07:08:48.043828151 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze_16\n",
      "2023-12-14 07:08:48.043831681 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze_14\n",
      "2023-12-14 07:08:48.043834475 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze_13\n",
      "2023-12-14 07:08:48.043838738 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze_11\n",
      "2023-12-14 07:08:48.043843071 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze_10\n",
      "2023-12-14 07:08:48.043846485 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze_8\n",
      "2023-12-14 07:08:48.043849985 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze_7\n",
      "2023-12-14 07:08:48.043853483 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze_1\n",
      "2023-12-14 07:08:48.043857039 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze_5\n",
      "2023-12-14 07:08:48.043860257 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node /Unsqueeze_4\n",
      "[W] colored module is not installed, will not use colors when logging. To enable colors, please install the colored module: python3 -m pip install colored\n",
      "[W] It looks like this model contains foldable nodes that produce large outputs.\n",
      "In order to avoid bloating the model, you may want to set a constant-folding size threshold.\n",
      "Note: Large tensors and their corresponding sizes were: {'/pos_embedding/MatMul_output_0': '2 MiB', 'center_pos_embedding': '2 MiB'}\n",
      "[I]     Total Nodes | Original:   697, After Folding:   152 |   545 Nodes Folded\n",
      "[I] Folding Constants | Pass 2\n",
      "[I]     Total Nodes | Original:   152, After Folding:   152 |     0 Nodes Folded\n",
      "[I] Saving ONNX model to: findCenter_folded.onnx\n",
      "[I] New Model:\n",
      "    Name: torch_jit | ONNX Opset: 14\n",
      "    \n",
      "    ---- 1 Graph Input(s) ----\n",
      "    {input_tensor [dtype=float32, shape=(1, 256, 180, 180)]}\n",
      "    \n",
      "    ---- 6 Graph Output(s) ----\n",
      "    {ct_feat [dtype=float32, shape=(1, 3000, 256)],\n",
      "     center_pos_embedding [dtype=float32, shape=(1, 3000, 256)],\n",
      "     out_scores [dtype=float32, shape=(6, 1, 500)],\n",
      "     out_labels [dtype=int64, shape=(6, 1, 500)],\n",
      "     out_orders [dtype=int64, shape=(6, 1, 500)],\n",
      "     out_masks [dtype=bool, shape=(6, 1, 500)]}\n",
      "    \n",
      "    ---- 112 Initializer(s) ----\n",
      "    \n",
      "    ---- 152 Node(s) ----\n",
      "    \n",
      "[I] PASSED | Runtime: 1.016s | Command: /usr/local/bin/polygraphy surgeon sanitize findCenter.onnx --fold-constants --output findCenter_folded.onnx\n",
      "gen findCenter.onnx success!\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import numpy as np\n",
    "\n",
    "if FINDCENTER_GEN_ONNX:\n",
    "    model_name = \"findCenter.onnx\"\n",
    "    # dummy_input=torch.randn(x.shape, requires_grad=True).cuda()\n",
    "    dummy_input = torch.as_tensor(np.ones([1, 256, 180, 180]), dtype=torch.float32)\n",
    "    torch.onnx.export(centerFinder, (dummy_input), model_name,\n",
    "                input_names=['input_tensor'], \n",
    "                output_names=['ct_feat', 'center_pos_embedding', 'out_scores', 'out_labels', 'out_orders', 'out_masks'],\n",
    "                export_params=True, \n",
    "                do_constant_folding=True,\n",
    "                opset_version=14,\n",
    "                )\n",
    "    \n",
    "    # !export POLYGRAPHY_AUTOINSTALL_DEPS=1\n",
    "    !polygraphy surgeon sanitize findCenter.onnx --fold-constants --output findCenter_folded.onnx\n",
    "\n",
    "    onnx.checker.check_model(onnx.load(\"findCenter_folded.onnx\"))\n",
    "    print(\"gen findCenter.onnx success!\")\n",
    "else:\n",
    "    print(\"pass\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "centerformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
